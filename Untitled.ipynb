{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a3a55d-260f-4078-86b7-7348498f53a6",
   "metadata": {},
   "source": [
    "# Question 1 \n",
    "fetch the content of a news article, using BeautifulSoup to interact with the HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b19065-cd22-4f28-a34c-32e209a1b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bs4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "def get_article_content(url='https://www.ynet.co.il/laisha/article/b1al4tzyp'):\n",
    "    # Given a URL, this function will return the article content in a string form\n",
    "    # as well as saving the content to a file.\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Fetch the text via the class name (might need to change it for other websites)\n",
    "    # This class name is applicable for some articles on ynet.co.il\n",
    "    class_name = 'public-DraftEditor-content' \n",
    "    article_content = soup.find('div', {'class': class_name})\n",
    "    \n",
    "    if article_content:\n",
    "        article_text = article_content.get_text()\n",
    "        print(\"The content was saved to a file\")\n",
    "        with open('article_content.txt', 'w', encoding='utf-8') as file:\n",
    "            file.write(article_text)\n",
    "        # return article_text\n",
    "    else:\n",
    "        print('Article content wasnt fetched')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f450b0c-561d-4e16-8916-1d0b9ff844f0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Question 2\n",
    "## Idea\n",
    "I approached the problem in following way:\n",
    "1. Use regex in order to identify the words that represent a number in hebrew within a text, using a set of indicative words\n",
    "2. Translate those words into English\n",
    "3. Convert the English words into integers\n",
    "4. Replace the Hebrew words in the original text with their corresponding integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42941ab2-e32a-48b8-be27-4a03732bce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "heb_numbers_keywords = ['אחת', 'שתיים', 'שלוש', 'ארבע', 'חמש', 'שש', 'שבע', 'שמונה', 'תשע', 'עשר', 'עשרה', 'עשרים',\n",
    "                        'שלושים', 'ארבעים', 'חמישים', 'שישים', 'שבעים', 'שמונים', 'תשעים', 'מאה', 'מאתיים', 'שלוש מאות',\n",
    "                        'ארבע מאות', 'חמש מאות', 'שש מאות', 'שבע מאות', 'שמונה מאות', 'תשע מאות', 'אלף', 'אלפיים',\n",
    "                        'שלושת אלפים', 'ארבעת אלפים', 'חמשת אלפים', 'ששת אלפים', 'שבעת אלפים', 'שמונת אלפים',\n",
    "                        'תשעת אלפים', 'עשרת אלפים', 'מיליון', 'אחת', 'אחד',  'שתי', 'שתיים', 'שניים', 'שלוש',\n",
    "                        'שלושה', 'ארבע', 'ארבעה', 'חמש', 'חמישה', 'שש', 'שישה', 'שבע', 'שבעה', 'שמונה', 'תשע', 'תשעה',\n",
    "                        'עשר', 'עשרה']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed4aa413-69f5-4393-baff-913a13d2c7b4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install word2number\n",
    "from word2number import w2n\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b2c47f-b477-4bfc-9b3f-3982c6bba649",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "The function find_sequences recieves two arguments: the text to search in and the list of words to search for.\n",
    "This regex was designed with hebrew linguistics in mind, capturing single words that represent a number of a \"string\" of words that together form a number i.e \"מאה חמישים ושלוש\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9397f25f-1902-48c8-b509-2a0910676ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sequences(sentence, words):\n",
    "    pattern = r'\\b(?:[א-ת]?' + '|[א-ת]?'.join(words) + r')(?:\\s(?:ו?' + '|ו?'.join(words) + r'))*\\b'\n",
    "    matches = re.findall(pattern, sentence)\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9d753f5-0757-4dde-a192-aff293d5609c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['מאה חמישים ושלוש', 'מאתיים ארבעים ושתיים', 'שבעים ושבע']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the find_sequence function\n",
    "s1= \"מאה חמישים ושלוש סתם בדיקה\"\n",
    "s2= \" בדיקה מאתיים ארבעים ושתיים\"\n",
    "s3= \"שבעים ושבע כגדכג\"\n",
    "res = []\n",
    "for s in [s1,s2,s3]:\n",
    "    res+= find_sequences(s, heb_numbers_keywords )\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee4e82f-4cd7-4715-8eea-83d418bce431",
   "metadata": {},
   "source": [
    "The translation function from hebrew to english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e51bdf38-276b-43cd-a105-2ef2cafb35ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install translate\n",
    "from translate import Translator\n",
    "\n",
    "def translate_hebrew_to_english(text):\n",
    "    translator = Translator(to_lang=\"en\", from_lang=\"he\")\n",
    "    translation = translator.translate(text)\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861a9c50-0670-4e66-97ae-04f18f8f21c6",
   "metadata": {},
   "source": [
    "Putting everything together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36207477-1214-47a7-b2c1-03086cb49371",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def question2(text):\n",
    "    # Contains the hebrew words representing numbers\n",
    "    words_to_replace = find_sequences(text, heb_numbers_keywords)\n",
    "    # Translation of each of the hebrew words representing numbers\n",
    "    eng_version = [translate_hebrew_to_english(w) for w in words_to_replace]\n",
    "    # List that will contain the corresponding numbers in integer form\n",
    "    nums = []\n",
    "    for w in eng_version:\n",
    "        try:\n",
    "            nums.append(w2n.word_to_num(w))\n",
    "        except ValueError:\n",
    "            # One of the values wasn't translated correctly, or the string is not a number\n",
    "            nums.append('')\n",
    "            pass\n",
    "\n",
    "    eng_heb_dict = list(zip(eng_version, words_to_replace, nums))\n",
    "    sorted_words = sorted(eng_heb_dict, key=lambda x: len(x[1]), reverse=True)\n",
    "    modified_text = ''\n",
    "    for t in sorted_words:\n",
    "        old_text_heb = t[1]\n",
    "        if t[0] == '':\n",
    "            # Something went wrong with translation, keep the original word\n",
    "            new_text_num = t[1]\n",
    "        else:\n",
    "            # Translation was successful\n",
    "            new_text_num = str(t[2])\n",
    "        modified_text = text.replace(old_text_heb, new_text_num)\n",
    "    return modified_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69c9c0de-951c-4c79-9311-ee4ed68b2be7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The content was saved to a file\n",
      "The modified file has been created\n"
     ]
    }
   ],
   "source": [
    "def example2():\n",
    "    get_article_content()\n",
    "    with open('article_content.txt', 'r') as file:\n",
    "        file_content = file.read()\n",
    "        modified_content = question2(file_content)\n",
    "        with open('modified_content.txt', 'w') as mod_file:\n",
    "            mod_file.write(modified_content)\n",
    "        print('The modified file has been created')\n",
    "# example2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80475721-092c-455d-810a-082fdec94abc",
   "metadata": {},
   "source": [
    "# Question 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05b34da",
   "metadata": {},
   "source": [
    "## Assumptions:\n",
    "Numeric value describing the quantity of an object appears after the object.\n",
    "\n",
    "## Flow\n",
    "1. parse the text, identify numeric values.\n",
    "2. whenever encountering a numeric value, that follows a word save it as a tuple within a list of results.\n",
    "3. save all of the saved results into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ff16cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_num_word_tuple(text):\n",
    "    # a regex that searches for a number followed by a space and another word.\n",
    "    # it excepts also prefix for the number\n",
    "    pattern = r'\\b[א-ת]*(\\d+)\\s*([a-zA-Zא-ת]+)\\b'\n",
    "    matches = re.findall(pattern, text)\n",
    "    results = []\n",
    "    for match in matches:\n",
    "        number, word = match\n",
    "        results.append((number,word))\n",
    "        print(f\"Number: {number}, Word: {word}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4db8d139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def is_noun(heb_word):\n",
    "    translated = translate_hebrew_to_english(heb_word)\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "    words = word_tokenize(word)\n",
    "    tagged_words = pos_tag(words)\n",
    "    \n",
    "    # Check if the first word is tagged as a noun (NN or NNS)\n",
    "    if tagged_words and tagged_words[0][1] in ['NN', 'NNS']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07055b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number: 7, Word: באוקטובר\n",
      "Number: 2, Word: שאר\n",
      "Number: 26, Word: באוקטובר\n",
      "Number: 5, Word: דקות\n",
      "Number: 2, Word: אמניות\n",
      "Number: 2, Word: שצריך\n",
      "Number: 7, Word: באוקטובר\n",
      "Number: 14, Word: מחזיקה\n",
      "Number: 84, Word: מנחל\n",
      "Number: 25, Word: שנה\n",
      "Number: 2, Word: בנות\n",
      "Number: 20, Word: ו\n",
      "Number: 12, Word: ברמת\n",
      "Number: 2, Word: את\n",
      "Number: 3, Word: צפייה\n",
      "Number: 2, Word: שאני\n",
      "Number: 2, Word: את\n",
      "Number: 2, Word: שכל\n",
      "Number: 22, Word: הקמתי\n",
      "Number: 27, Word: עזבה\n",
      "Number: 2, Word: קלטות\n",
      "Number: 2, Word: שמתייחסים\n",
      "Number: 2, Word: אותו\n",
      "Number: 15, Word: שנה\n",
      "Number: 70, Word: לאבא\n",
      "Number: 3, Word: צפייה\n",
      "Number: 2015, Word: יחד\n",
      "Number: 2, Word: הצגות\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dean/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/dean/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'word' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb#X23sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmodified_content.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m modified_file:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb#X23sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         content \u001b[39m=\u001b[39m modified_file\u001b[39m.\u001b[39mread()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb#X23sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         question3(content)\n",
      "\u001b[1;32m/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb Cell 18\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m results \u001b[39m=\u001b[39m find_num_word_tuple(text)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m filter_nouns_func \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: \u001b[39mTrue\u001b[39;00m \u001b[39mif\u001b[39;00m is_noun(x[\u001b[39m1\u001b[39m]) \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mfilter\u001b[39;49m(filter_nouns_func,results))                \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(results)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m data \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mNumber\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39mint\u001b[39m(results[i][\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n)], \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWord\u001b[39m\u001b[39m\"\u001b[39m: [results[i][\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m (n)]}\n",
      "\u001b[1;32m/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb Cell 18\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mquestion3\u001b[39m(text):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# the given text is after the processing done in question2, therefore we can look for numeric values\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     results \u001b[39m=\u001b[39m find_num_word_tuple(text)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     filter_nouns_func \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: \u001b[39mTrue\u001b[39;00m \u001b[39mif\u001b[39;00m is_noun(x[\u001b[39m1\u001b[39;49m]) \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mfilter\u001b[39m(filter_nouns_func,results))                \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(results)\n",
      "\u001b[1;32m/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m nltk\u001b[39m.\u001b[39mdownload(\u001b[39m'\u001b[39m\u001b[39mpunkt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m nltk\u001b[39m.\u001b[39mdownload(\u001b[39m'\u001b[39m\u001b[39maveraged_perceptron_tagger\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m words \u001b[39m=\u001b[39m word_tokenize(word)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m tagged_words \u001b[39m=\u001b[39m pos_tag(words)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dean/SynologyDrive/finding-a-job/data-mer60/heb_words/Untitled.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Check if the first word is tagged as a noun (NN or NNS)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def question3(text):\n",
    "    # the given text is after the processing done in question2, therefore we can look for numeric values\n",
    "    results = find_num_word_tuple(text)\n",
    "    filter_nouns_func = lambda x: True if is_noun(x[1]) else False\n",
    "    results = list(filter(filter_nouns_func,results))                \n",
    "    n = len(results)\n",
    "    data = {\"Number\": [int(results[i][0]) for i in range(n)], \n",
    "            \"Word\": [results[i][1] for i in range (n)]}\n",
    "    df = pd.DataFrame(data)\n",
    "    print(df)\n",
    "    return df\n",
    "\n",
    "with open('modified_content.txt', 'r') as modified_file:\n",
    "        content = modified_file.read()\n",
    "        question3(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac0f9d1",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "In order to sort all the articles by their level \"closeness\" to a single article chosen, we will have to define some metrics.\n",
    "\n",
    "## Phase 0 - Preprocessing\n",
    "For each article:\n",
    "1. Convert each word to its original form, such as \"רוה\"מ\" -> \"ראש הממשלה\" and \"כלבים\" -> \"כלב\"\n",
    "2. Remove \n",
    "## Phase 1 - embedding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
